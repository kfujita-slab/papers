\chapter{理論}
本章では、システムの実装に用いる理論についての説明を行う。
\section{ニューラルネットワーク}
ニューラルネットワーク(Neural Network)は、生物の脳内におけるニューロン(神経細胞)の結びつき方をモデルにした情報処理システムである。
学習能力を持つため、サンプルとなるデータに基づき必要とされる機能を自動形成できる。
\begin{figure}[hbt]
    \centering
    \includegraphics[width=7cm,clip]{image/neuron_image.pdf}
    \caption{各ニューロンにおけるプロセスの模式図$(n=2)$}
    \label{fig:neuron_image}
\end{figure}

ニューラルネットワークを構成するニューロンの模式図を、前段のニューロン数$n$が2の
ときを例として
図\ref{fig:neuron_image}に示す。ニューロン$i$の出力$y_i$は、入力$x_j\ (1\leq j\leq n)$を基に、\ref{conv_math}式により決定される。
\begin{equation}
    \label{conv_math}
    y_i = h(b_i + \sum_{j=1}^{n}x_jw_{i,j} )
\end{equation}

各入力$x_j$には固有の値である重み$w_{i,j}$が設定され、同じく固有の値であるバイアス$b_i$と共に計算に用いられる。
この固有の値がニューラルネットワークの機能を決定づける要素であり、適切な値に設定することで必要とする機能を形成する。
また、$h$は活性化関数と呼ばれる関数であり、以下のような非線形関数が用いられることが多い。
%\begin{equation}
%    \label{sigmoid}
%    h(x) = (1 + \mathrm{e}^{-x})^{-1}\quad (標準シグモイド関数)
%\end{equation}
%\begin{equation}
%    \label{ReLU}
%    h(x) = \max(0,x)\quad(\mathrm{ReLU})
%\end{equation}
\begin{align}
    \label{sigmoid}
    h(x) &= (1 + \mathrm{e}^{-x})^{-1}\quad (標準シグモイド関数) \\
    \label{ReLU}
    h(x) &= \max(0,x)\quad\quad(\mathrm{ReLU})
\end{align}

\begin{figure}[hbt]
    \centering
    \includegraphics[width=7cm,clip]{image/NN_image.pdf}
    \caption{ニューラルネットワークの例}
    \label{fig:NN_image}
\end{figure}

ニューラルネットワークの代表的な構造として、順伝播型ニューラルネットワークの1種である多層パーセプトロンを例に挙げる。
中間層が1層以上存在する多層パーセプトロンでは、任意の連続関数を近似可能であることが知られている。
%ただし、活性化関数に線形関数を用いた場合、どんなに層を増やしたとしてもそれと等価な単層ネットワークが存在するため、
ただし、線形な関数のみで構成されるネットワークは、
どんなに層を増やしたとしても
それと等価な単層ネットワークが存在するため、
層を増やす恩恵を得るには非線形な関数が各層で用いられる必要がある。
そのため、一般的に活性化関数には非線形関数が用いられている。

先述した通り、ニューラルネットワークで期待される機能を実現するには、各ニューロンの重みとバイアスを適切に設定しなければならない。この調整をデータに基づいて自動で行う仕組みが学習である。
学習には大きく分けて教師あり学習と教師なし学習があるが、ここでは教師あり学習について説明を行う。

教師あり学習では、入力データと教師データが対になって与えられたデータセットを利用し、ネットワークに入力データを渡した際の出力が教師データと
一致するように重みやバイアスを変化させていく。
一般的に、出力精度の指標としては2乗和誤差や交差エントロピー誤差などの損失関数が、学習手法としては誤差逆伝播法が用いられる。
$k$番目の入力データに基づく出力を$y_k$、それと対応する教師データを$t_k$として以下に
損失関数の例を示す。
\begin{align}
    \centering
     E &= \frac{1}{2} \sum_{k} {(y_k - t_k)}^2 \quad(2乗和誤差)\\
     E &= - \sum_k t_k \log y_k \quad ( 交差エントロピー誤差)
\end{align}

損失関数とは、出力精度の低さを示す指標であり、
これによって得られた誤差を最小とするように重みおよびバイアスを変更する。
また、重みに基づいて誤差を逆伝播させ、中間層の重みおよびバイアスを順次更新していく。
損失関数は逆伝播可能な関数でなくてはならず、活性化関数との
組み合わせによっては学習が遅くなることもある。
上記の損失関数は逆伝播可能で、
%式\ref{sigmoid},\ref{ReLU}で示した
一般的な活性化関数と組み合わせての利用に適しており、
最尤推定に則った損失関数であるためよく用いられている。
%損失関数を用いる理由だが、例えば物体認識を行うニューラルネットワークの精度評価を正答率とした場合、
%パラメータの更新に対する正答率の変化は離散的な値しか観測できず、パラメータの更新はある地点で停止することになる。
%このように、微小な変更に対して正しい精度評価を得るために損失関数が用いられている。

\section{畳み込みニューラルネットワーク}
畳み込みニューラルネットワーク(Convolutional Neural Network：CNN)は、
図\ref{fig:NN_image}に示したような、隣接する層の全ニューロン間で
結合がある(全結合)ニューラルネットワークとは異なり、入力と設定されたフィルタの畳み込み演算に基づいて出力の決定を行うニューラルネットワークの一種である。
画像認識や音声認識などCNNの活用形態は多岐にわたり、
本研究においても画像認識を目的としてCNNを利用している。本項では、
本研究で行われる2次元画像への適用を例としてCNNについて説明を行う。

画像認識における全結合ネットワークには、空間的情報が失われるという問題点がある。
入力が2次元画像の場合、空間的に近いピクセルは似たような値である、距離の離れたピクセルは互いに影響を及ぼさない、画素のRGB値には密接な関連があるなど、空間的形状には汲み取るべき本質的なパターンが含まれていると考えられる。
しかし全結合層はこのような形状を無視し、すべて同等のニューロンとして処理を行う
ため、空間的情報を生かすことができない。

そこでCNNは形状を維持するために畳み込み層を利用する。
畳み込み層で行われる畳み込み演算は、
%具体的な処理を図\ref{fig:convolution}に示す。
$n\times n$サイズの入力画像を$X(i,j)$、
$m\times m$サイズのフィルタを$F(i,j)$として、式\ref{eq:conv}の
ように定義できる。
\begin{equation}
\label{eq:conv}
(X \ast F)(i,j) = \sum^{m-1}_{k=0} \sum^{m-1}_{l=0}X(i+k,j+l)F(k,l)
\end{equation}
また、$n=4,m=3$として、畳み込み層全体の処理を図\ref{fig:convolution}に示す。
\begin{figure}[hbt]
    \centering
    \includegraphics[width=13cm,clip]{image/convolution.pdf}
    \caption{畳み込み層：畳み込み演算を「＊」で表記}
    \label{fig:convolution}
\end{figure}

%\noindent なお、$n\times n$サイズの入力画像$X(i,j)$と、
%$m\times m$サイズのフィルタ$F(i,j)$の畳み込み演算の定義は式\ref{eq:conv}の
%ように表せる。
%\begin{equation}
%\label{eq:conv}
%(X \ast F)(i,j) = \sum^{m-1}_{k=0} \sum^{m-1}_{l=0}X(i+k,j+l)F(k,l)
%\end{equation}
%
%式もほしいーーーー
%\begin{equation}
%    
%\end{equation}
%

以上のように、フィルタと入力データの対応する要素の積和演算を行い、対応する場所へ格納していく。
このフィルタこそが重みに対応するパラメータであり、フィルタの値がCNNの動作を決定付ける。バイアスは全結合ニューラルネットワークと同様に、
フィルタ(重み)の適用後に加算される。

図\ref{fig:convolution}でも示されるように、フィルタの適用により出力(特徴マップ)は
入力データに比べて一回り小さくなる。これを回避するために、入力データの端に0を
追加する(ゼロパディング)操作を加える場合がある。
図\ref{fig:convolution}のようにフィルタの大きさが3$\times$3かつ、
フィルタの適用範囲を動かす量(ストライド)が1ならば、
幅1のパディングにより
入力と出力の大きさを一致させることができる。
フィルタやストライドの大きさが変化する場合は、それを考慮してパディングの
大きさも変化させる必要がある。

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm,clip]{image/maxpooling.pdf}
    \caption{pooling (max pooling)}
    \label{fig:maxpooling}
\end{figure}

CNNを利用したアプリケーションでは、位置不変性(パターンの位置がずれていても影響を受け辛い性質)が求められることが多く、その際にはpooling層と呼ばれる新たな層がネットワークに追加される。画像を一定サイズの領域に区切り、各領域を
図\ref{fig:maxpooling}のように、最大値や平均値を用いて1画素に置き換える(pooling)ことで、パターンのずれを吸収させ、位置不変性を高める。
その処理内容からわかる通り、pooling層において学習するパラメータはなく、層間における
画素ごとのニューロン数(チャネル)の変化もない。ただし、縦横方向の空間は小さくなるため、画素ごとの位置情報は失われる。よって、
元々の位置情報が必要となるアプリケーションなどでは注意が必要となる。

\section{セマンティックセグメンテーション}
一般的なCNNによる物体認識は、画像全体に対して何らかの判定・分類を行うものが多い。
例としては、写真群から猫が写っている画像だけを抽出する機能などが挙げられる。
一方で、セマンティックセグメンテーションは画素ごとに判定・分類を行う。
例えば、複数の物体が写っている写真に対して、猫が写っている部分だけ塗りつぶしを行う機能が挙げられる。
図\ref{fig:segment_cat}に示すセグメンテーション例では、
猫とソファが区別されて塗り分けられている様子が確認できる。

\begin{figure}[hbt]
    \centering
    \includegraphics[width=10cm,clip]{image/segment_cat.pdf}
    \caption{セグメンテーションの例：\cite{segment_example}より引用}
    \label{fig:segment_cat}
\end{figure}

1画素だけを見てその画素が何にあたるか判定するのは通常不可能であるため、周辺画素ひいては画像全体を見て判定する必要がある。
%そこで画素の空間的情報を用いられるCNNの出番となるのだが、ここで一つ問題が発生する。
%CNNではpooling層の適用によって画素の位置情報が失われてしまうことだ。
そこで、CNNによる空間的情報を利用した判定を行うのだが、
pooling層を適用する場合、画素の位置情報が破棄されるという問題が発生する。

医用画像セグメンテーションを目的としたネットワークであるU-Net\cite{U-Net}では、
poolingによって縮小された特徴マップを
後段で拡張することによって位置情報の復元を行う。
この操作はpoolingに対してunpoolingと呼称される。
\begin{figure}[hbt]
    \centering
    \includegraphics[width=10cm,clip]{image/unpooling.pdf}
    \caption{unpooling}
    \label{fig:unpooling}
\end{figure}
U-Netにおけるunpooling処理を図\ref{fig:unpooling}に示す。
poolingの際に最大値だった画素の位置を保持し、
unpoolingでは保持された位置を利用して拡張を行う。
また、U-Netはpooling層に通す前の特徴マップを後段に直接連結させることで、
粗大化を避けられないunpooling層の出力を補佐し、
セグメンテーションの精度を高めている。
%なお、本研究で実装するセグメンテーションシステムは、U-Netを基盤としたネットワークによって構築されている。
\section{FPGA}
Field Programmable Gate Array\ (FPGA)は、製造後に設計者が構成を設定できる
集積回路である。
FPGAは、複数入力のルックアップテーブル(LUT)等で構成された論理ブロックを
多数搭載し、LUTを書き換えることによって論理積や論理和といった様々な論理を
表現できる。
また、論理ブロック間を結ぶ内部配線についても構成を変化させることができるため、
設計者は論理を表現したブロックを適切に組み合わせることによって任意の論理回路を実装する。

FPGAを用いたハードウェア設計は、一般的にVelilog HDLやVHDLといったハードウェア記述言語で行われる。
用途に合わせて設計される集積回路である
ASIC (Application Specific Integrated Circuit)に比べ、
集積密度や電力効率、動作速度では劣る一方、
開発・製造期間は短く、設計の変更も容易である。
また、コスト面に関しても、製造のための初期コストは不要であり、
FPGA自体は汎用品であることから、少量生産においては生産コストでも有利である。

一般的に、ソフトウェアで動画像処理をするときは、
動作クロック周波数の高い高性能CPUが必要となる。
一方ハードウェアは、回路を並列化やパイプライン化することで
処理性能を上げることができ、ソフトウェアと比較して低い動作クロックで
同等の処理性能を実現できる。そのため、画像処理システムにはFPGAを始めとする
ハードウェアが用いられることが多い。
また、計算分野によっては処理の並列化特性から高性能なCPU・GPUよりも高速に動作
する可能性がある\cite{tsunami}。CNNもチャネル方向の並列化に加え、
画素情報を順次走査で受け取りながらのストリーム処理が可能な点から
ハードウェアに適した計算処理であるといえる。

%\subsection{サブセクション}
%関連論文\cite{sample}.
%
%図の参照、図\ref{fig:yoshiki}
%
%表の参照、表\ref{tab:sample}
%
%\begin{figure}[hbt]
%    \centering
%    \includegraphics[scale=1.0,clip]{image/yoshiki_nico.jpg}
%    \caption{Sample図}
%    \label{fig:yoshiki}
%\end{figure}
%
%
%\begin{table}[hbt]
%    \caption{Sample表}
%    \centering
%    \begin{tabular}{|c||c|c|c|c|c|}
%        \hline
%        & XXX & XX & XXXXX & XXXX & XXXX\\
%        \hline\hline
%        XXXX     & xxx & xxx & xxxx & xx & xx \\\hline
%        XXXXX & xxx & xxx & xxxx & xx & xx \\\hline   
%    \end{tabular}
%    \label{tab:sample}
%\end{table}






